{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db2bffa2-0d7c-4652-a20f-7fe20d53ce85",
   "metadata": {},
   "source": "# Modeling Non-Linear Patterns with Activation Functions\n\nWelcome back to the delivery challenge!\n\nIn the last lab, your simple linear model performed well on bike-only data, but it struggled when cars were added. The reason was simple: your model could only learn **straight lines**, but the new data followed a **curve**. As you saw in the lectures, simply adding more linear neurons is not the solution. The model's output would still be a straight line.\n\nThis is where **non-linear activation functions** come in. They are the key to unlocking your model's ability to learn the complex, curved patterns found in real-world data. In this lab, you'll use the most popular and powerful activation function, **ReLU (Rectified Linear Unit)**, to build a more sophisticated model. By adding a ReLU activation, your model can create multiple \"bends\" that can approximate the complex delivery time curve.\n\nIn this lab, you will:\n\n* Prepare the combined bike and car delivery data, this time applying a technique called **normalization** to help your model train more effectively.\n* Build a *non-linear* neural network using the **ReLU** activation function.\n* Train your new model to learn the complex, curved relationship in the data.\n* Predict delivery times using your new model and see if it can finally succeed where the linear one failed."
  },
  {
   "cell_type": "markdown",
   "id": "370c6ff6-cead-4fd2-a369-2f762fc25edc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573ecbf-edab-462d-8a43-3b747d6b8ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import helper_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5457c73-17b2-4915-a867-5c921b661a28",
   "metadata": {},
   "source": [
    "## Preparing the Non-Linear Data\n",
    "\n",
    "Start by loading the same dataset that caused problems at the end of the last lab. This is the combined data for both bike and car deliveries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d55db-a1cd-413e-9291-1131db823c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined dataset: bikes for short distances, cars for longer ones\n",
    "distances = torch.tensor([\n",
    "    [1.0], [1.5], [2.0], [2.5], [3.0], [3.5], [4.0], [4.5], [5.0], [5.5],\n",
    "    [6.0], [6.5], [7.0], [7.5], [8.0], [8.5], [9.0], [9.5], [10.0], [10.5],\n",
    "    [11.0], [11.5], [12.0], [12.5], [13.0], [13.5], [14.0], [14.5], [15.0], [15.5],\n",
    "    [16.0], [16.5], [17.0], [17.5], [18.0], [18.5], [19.0], [19.5], [20.0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Corresponding delivery times in minutes\n",
    "times = torch.tensor([\n",
    "    [6.96], [9.67], [12.11], [14.56], [16.77], [21.7], [26.52], [32.47], [37.15], [42.35],\n",
    "    [46.1], [52.98], [57.76], [61.29], [66.15], [67.63], [69.45], [71.57], [72.8], [73.88],\n",
    "    [76.34], [76.38], [78.34], [80.07], [81.86], [84.45], [83.98], [86.55], [88.33], [86.83],\n",
    "    [89.24], [88.11], [88.16], [91.77], [92.27], [92.13], [90.73], [90.39], [92.98]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a876028f-5b61-4af0-8d32-c3e69c07ae7c",
   "metadata": {},
   "source": [
    "* As you will see from running the code below, the data plot follows a non-linear pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f406a0ac-8fe2-4ce3-ad9b-6794c03bc8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_utils.plot_data(distances, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6240a23-0535-4146-80cf-edc54b76f443",
   "metadata": {},
   "source": "### A New Step: Normalizing the Data\n\nBefore building your model, you will apply a quick data preparation step called **normalization**. This is a standard technique that makes the training process more stable and effective by adjusting the scale of the data. This adjustment helps prevent large distance values from dominating the learning process and keeps gradients stable during training. You will explore this topic in greater detail in a later module.\n\n* You will calculate the mean and standard deviation for the `distances` and `times` tensors.\n* You will then apply standardization to each tensor using its respective mean and standard deviation, which creates new normalized tensors named `distances_norm` and `times_norm`.\n* This specific technique is called **standardization** (or z-score normalization), which converts the original data from `1.0 to 20.0 miles` and approximately `7 to 93 minutes` into a new, normalized scale."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a658b891-2f72-4276-95c0-aa5c90c2509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation for the 'distances' tensor\n",
    "distances_mean = distances.mean()\n",
    "distances_std = distances.std()\n",
    "\n",
    "# Calculate the mean and standard deviation for the 'times' tensor\n",
    "times_mean = times.mean()\n",
    "times_std = times.std()\n",
    "\n",
    "# Apply standardization to the distances.\n",
    "distances_norm = (distances - distances_mean) / distances_std\n",
    "\n",
    "# Apply standardization to the times.\n",
    "times_norm = (times - times_mean) / times_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d663c-48ad-434c-b9a9-ad72f97758a2",
   "metadata": {},
   "source": [
    "* You will notice the axes now show the data on a new, normalized scale, with distance ranging from approximately `-1.7 to 1.7` and time from `-2.0 to 1.0`.\n",
    "* Despite this change in scale, the underlying curved pattern of the data remains exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be25d9f4-aa18-4076-905a-65b8045e85ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_utils.plot_data(distances_norm, times_norm, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24db88b3-f405-4ded-a349-8919fc82df48",
   "metadata": {},
   "source": "## Building the Non-Linear Model\n\nWith your normalized data ready, you can now build a model capable of learning its curved pattern. You will define the model's architecture, which now includes a `ReLU` activation function. This structure is what gives your model the ability to learn non-linear relationships.\n\n* `nn.Linear(1, 3)`: This is your **first hidden layer**. It consists of three neurons, each receiving one input feature (the normalized distance). This layer transforms the single input value into three separate values.\n* `nn.ReLU()` applies the ReLU activation function to the output of each of the three neurons from the hidden layer. This is the crucial non-linear step that allows your model to create \"bends\" and learn curves instead of just straight lines.\n* `nn.Linear(3, 1)`: This is your **output layer**. It takes the three activated values from the previous step as its input and combines them to produce a single final output, which is your predicted (normalized) delivery time.\n\nThis creates a neural network with 1 hidden layer containing 3 neurons."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e10330-dffe-41d8-8de9-7181bdf0f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line ensures that your results are reproducible and consistent every time.\n",
    "torch.manual_seed(27)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(3, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ab5db-3973-4c68-a07a-f48b11a16d79",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "* Define the loss function and the optimizer for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e02f988-6658-4804-b1b7-c792e5e061e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992027ad-ca3b-4717-aa69-9256b2cfa34c",
   "metadata": {},
   "source": "With your model and training tools ready, you can begin the training process.\n\n* You will run the training loop for `3000` epochs (more than Lab 1 because the non-linear pattern is more complex and requires more training). This will repeatedly feed the *normalized* data to your model, measure the error, and adjust the model's parameters to improve its predictions.\n* The second half of the code includes a live plot, allowing you to watch in real time as your model's prediction line adapts to fit the curved data. The live plot helps you see how your model gradually learns to fit the curve, starting with a poor fit and improving over time.\n\n**IMPORTANT NOTE**: As the plot updates in real time during training, you might notice a flickering effect. This is the expected behavior of the live visualization and not an issue with your screen."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a280d-24c7-4cc9-8d5a-82806efbb2cd",
   "metadata": {},
   "outputs": [],
   "source": "# Training loop\nfor epoch in range(3000):\n    # Reset the optimizer's gradients\n    optimizer.zero_grad()\n    # Make predictions (forward pass)\n    outputs = model(distances_norm)\n    # Calculate the loss\n    loss = loss_function(outputs, times_norm)\n    # Calculate adjustments (backward pass)\n    loss.backward()\n    # Update the model's parameters\n    optimizer.step()\n\n    # Create a live plot every 50 epochs\n    if (epoch + 1) % 50 == 0:\n        helper_utils.plot_training_progress(\n            epoch=epoch,\n            loss=loss,\n            model=model,\n            distances_norm=distances_norm,\n            times_norm=times_norm\n        )\n\nprint(\"\\nTraining Complete.\")\nprint(f\"\\nFinal Loss: {loss.item()}\")"
  },
  {
   "cell_type": "markdown",
   "id": "438e385b-c4b6-4558-b55b-ade1c56c65d5",
   "metadata": {},
   "source": [
    "## Checking the Final Fit \n",
    "\n",
    "Now that training is complete, you will visualize the result.\n",
    "\n",
    "* You will plot your model's final predicted curve against the original data points.\n",
    "* This lets you visually inspect how well your non-linear model learned to fit the complex data pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc6755e-b2be-4946-9198-27daafe62e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_utils.plot_final_fit(model, distances, times, distances_norm, times_std, times_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387bf435-033d-4ee6-b6a9-bc202b2295c4",
   "metadata": {},
   "source": "<br>\n\nCongratulations! You have successfully trained your first **non-linear** neural network in PyTorch!\n\nWhere the simple linear model from the last lab failed, your new model with a `ReLU` activation function succeeded. As you can see from the plot, your model learned to capture the complex, curved relationship in the combined bike and car delivery data."
  },
  {
   "cell_type": "markdown",
   "id": "af1a1b42-b3fc-4267-919f-53c31b2c817a",
   "metadata": {},
   "source": "## Making a Prediction\n\nWith your fully trained non-linear model, you can now use it to make a prediction for a new delivery. The process is slightly different now because your model was trained on *normalized* data.\n\n* First, you will take the new input distance and **normalize** it using the same mean and standard deviation from your training data. This step is CRITICAL: your model has no idea about the original scales (miles and minutes). It only understands the normalized scale it was trained on.\n* After the model provides its prediction, you must **de-normalize** the output. This converts the prediction from its normalized scale back into an understandable value in minutes.\n* Finally, the code uses this actual predicted time to run the decision logic. For this prediction, assume your company now promises deliveries within 45 minutes (instead of 30 minutes from Lab 1) and wants to know which vehicle to use."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dafb08-23c4-409a-a030-b215985eb53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_to_predict = 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b0af90-83eb-4752-87e1-6cc8be734165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the torch.no_grad() context manager for efficient prediction\n",
    "with torch.no_grad():\n",
    "    # Normalize the input distance\n",
    "    distance_tensor = torch.tensor([[distance_to_predict]], dtype=torch.float32)\n",
    "    new_distance_norm = (distance_tensor - distances_mean) / distances_std\n",
    "    \n",
    "    # Get the normalized prediction from the model\n",
    "    predicted_time_norm = model(new_distance_norm)\n",
    "    \n",
    "    # De-normalize the output to get the actual time in minutes\n",
    "    predicted_time_actual = (predicted_time_norm * times_std) + times_mean\n",
    "    \n",
    "    # --- Decision Making Logic ---\n",
    "    print(f\"Prediction for a {distance_to_predict}-mile delivery: {predicted_time_actual.item():.1f} minutes\")\n",
    "    \n",
    "    # First, check if the delivery is possible within the 45-minute timeframe\n",
    "    if predicted_time_actual.item() > 45:\n",
    "        print(\"\\nDecision: Do NOT promise the delivery in under 45 minutes.\")\n",
    "    else:\n",
    "        # If it is possible, then determine the vehicle based on the distance\n",
    "        if distance_to_predict <= 3:\n",
    "            print(f\"\\nDecision: Yes, delivery is possible. Since the distance is {distance_to_predict} miles (<= 3 miles), use a bike.\")\n",
    "        else:\n",
    "            print(f\"\\nDecision: Yes, delivery is possible. Since the distance is {distance_to_predict} miles (> 3 miles), use a car.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d8413-83aa-466a-81e4-e38cfa824724",
   "metadata": {},
   "source": "## Conclusion\n\nYou have now built and trained both a simple linear model and a more powerful non-linear model in PyTorch. In this lab, you saw firsthand how adding a non-linear activation function like **ReLU** gave your model the ability to succeed where the linear model had failed.\n\nYou have moved beyond fitting straight lines and can now capture the complex, curved patterns that are common in real-world data. You also learned a practical data preparation technique, normalization, that helps make the training process more stable and effective.\n\nWith these fundamental skills of building architectures, preparing data, and training models, you are well prepared for the next step. In the upcoming module, you will build on this foundation to tackle new kinds of problems, like classification, and dive even deeper into the mechanics of how neural networks learn."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}